{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Layer\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from scipy.stats import percentileofscore\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../pipeline/tmp/cities/poz-w/dataset.parquet')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['to_x']\n",
    "y = df['to_y']\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.hist2d(x, y, bins=100, cmap='viridis')\n",
    "\n",
    "plt.colorbar(label='Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['from_x', 'from_y', 'to_x', 'to_y', 'day_type', 'start', 'reference']]\n",
    "y = df['time']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.body = Sequential([\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(2),\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        reference = inputs[:, 6]\n",
    "        mods = self.body(inputs[:, :6])\n",
    "        return reference * (1 + mods[:, 0]) + 15 * 60 * mods[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymetric_loss_function(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    tf.debugging.assert_greater(\n",
    "        tf.reduce_min(y_true), tf.constant(0.0, dtype=tf.float32),\n",
    "        message=\"y_true contains zero or negative values!\"\n",
    "    )\n",
    "\n",
    "    e = y_pred - y_true\n",
    "    se = e**2\n",
    "    loss = tf.where(e < 0, se, 64*se)\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.mse, metrics=['mape'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=16, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # Enable TensorFlow Lite ops.\n",
    "]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read tflite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.tflite', 'rb') as f:\n",
    "    tflite_model = f.read()\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "\n",
    "in_idx = interpreter.get_input_details()[0]['index']\n",
    "out_idx = interpreter.get_output_details()[0]['index']\n",
    "\n",
    "interpreter.resize_tensor_input(in_idx, (1, 7))\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predicitons on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    single_row = X_test.iloc[i].to_numpy().reshape(1, -1).astype(np.float32)\n",
    "    interpreter.set_tensor(in_idx, single_row)\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(out_idx)\n",
    "    y_pred.append(output_data[0])\n",
    "\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(f'Mean Absolute Percentage Error (MAPE): {mape:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize set results distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_difference = ((y_pred - y_test) / y_test) * 100\n",
    "\n",
    "percentile_1 = np.percentile(percentage_difference, 1)\n",
    "percentile_99 = np.percentile(percentage_difference, 99.9)\n",
    "max_overestimation = np.max(percentage_difference)\n",
    "percentile_of_0 = percentileofscore(percentage_difference, 0)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(percentage_difference, kde=True, bins=100, color='blue')\n",
    "\n",
    "plt.axvline(percentile_1, color='green', linestyle='--', linewidth=2, label=f'1st Percentile: {percentile_1:.2f}%')\n",
    "plt.axvline(percentile_99, color='red', linestyle='--', linewidth=2, label=f'99.9th Percentile: {percentile_99:.2f}%')\n",
    "\n",
    "plt.text(percentile_1, plt.ylim()[1] * 0.9, f'{percentile_1:.2f}%', color='green', ha='center')\n",
    "plt.text(percentile_99, plt.ylim()[1] * 0.9, f'{percentile_99:.2f}%', color='red', ha='center')\n",
    "\n",
    "plt.axvline(max_overestimation, color='purple', linestyle='--', linewidth=2, label=f'Max Overestimation: {max_overestimation:.2f}%')\n",
    "plt.text(max_overestimation, plt.ylim()[1] * 0.8, f'{max_overestimation:.2f}%', color='purple', ha='center')\n",
    "\n",
    "plt.xlabel('Percentage Difference (%)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Percentage Difference Between Predictions and Targets')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f'Maximal Overestimation Value: {max_overestimation:.2f}%')\n",
    "print(f'Percentile for 0 on x-axis value: {percentile_of_0:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward pass time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 10000\n",
    "total_time = 0\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    random_index = np.random.randint(0, X_test.shape[0])\n",
    "    # single_row = X_test.iloc[i].to_numpy().reshape(1, -1).astype(np.float64)\n",
    "    single_row = X_test.iloc[i].to_numpy().reshape(1, -1).astype(np.float32)\n",
    "    start_time = time.perf_counter()\n",
    "    interpreter.set_tensor(in_idx, single_row)\n",
    "    interpreter.invoke()\n",
    "\n",
    "    output_data = interpreter.get_tensor(out_idx)\n",
    "    end_time = time.perf_counter()\n",
    "    total_time += (end_time - start_time)\n",
    "\n",
    "average_forward_pass_time = (total_time / num_iterations) * 1e6\n",
    "print(f\"Average forward pass time for a single row using TensorFlow Lite: {average_forward_pass_time:.6f} microseconds\")\n",
    "print(f\"total time for 10000 rows: {total_time*1000} milliseconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
